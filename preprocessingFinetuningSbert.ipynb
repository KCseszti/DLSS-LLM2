{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1gxEmuYeyMj4iXVH3i5DR0srmy2160xOK","timestamp":1755781289890},{"file_id":"18q4UF0_ugYi561xi1z-igfrI8Z6cUuon","timestamp":1755762486250}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["This file builds a dataframe for SBERT."],"metadata":{"id":"iLud83jM4D6Z"}},{"cell_type":"code","source":["# import and install required libraries.\n","import requests\n","import os\n","from os import path\n","import csv\n","import random\n","import numpy as np\n","import pandas as pd\n","import time\n","import re\n","import random\n","import json\n","from sklearn.model_selection import train_test_split\n","from sentence_transformers.readers import InputExample"],"metadata":{"id":"lKAyj2esmn6Q","executionInfo":{"status":"ok","timestamp":1756376793348,"user_tz":-120,"elapsed":43,"user":{"displayName":"Jan","userId":"04834686519003542727"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# create mount point.\n","mount_dir = '/content/nextcloud'\n","os.makedirs(mount_dir, exist_ok=True)"],"metadata":{"id":"KdFefx_icVG1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["webdav_url = \"https://cloud.uni-konstanz.de/remote.php/dav/files/removed\"\n","username = \"removed\"\n","password = \"removed\""],"metadata":{"id":"A2d2xYtRcl8_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!curl -u \"removed!\" -o genius_cleaned_merged.json \"https://cloud.uni-konstanz.de/remote.php/dav/files/removed/genius_cleaned_merged.json\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c8YpTExHcnfn","executionInfo":{"status":"ok","timestamp":1755778248067,"user_tz":-120,"elapsed":1115,"user":{"displayName":"Nicole Kloss","userId":"01214507128086168572"}},"outputId":"80f40f1b-cd97-4a01-88d2-f80e75e25643"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 12.9M  100 12.9M    0     0  14.1M      0 --:--:-- --:--:-- --:--:-- 14.1M\n"]}]},{"cell_type":"code","source":["with open(\"genius_cleaned_merged.json\", \"r\") as f:\n","    data = json.load(f)\n","\n","df = pd.DataFrame(data)\n","\n","# keep only what I need: text + label\n","df = df[[\"lyrics_clean\", \"primary_tag\"]]\n","df = df.dropna().reset_index(drop=True)\n","\n","print(df.head())\n","print(len(df))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Anas2vZecUfz","executionInfo":{"status":"ok","timestamp":1756376129735,"user_tz":-120,"elapsed":381,"user":{"displayName":"Jan","userId":"04834686519003542727"}},"outputId":"cab94874-bb03-4e7a-88b0-4b76ca4c758f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["                                        lyrics_clean primary_tag\n","0  could sell organs chinese black market would e...         pop\n","1  undeniable together unbelievable used say fall...         r&b\n","2  set soul ease chased darkness view left desper...         pop\n","3  clap hands alright clap hands alright clap han...         pop\n","4  via billboard honor 25th anniversary billboard...         rap\n","9500\n"]}]},{"cell_type":"code","source":["print(df[\"primary_tag\"].value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uDlRJNl9hlWN","executionInfo":{"status":"ok","timestamp":1756376132361,"user_tz":-120,"elapsed":53,"user":{"displayName":"Jan","userId":"04834686519003542727"}},"outputId":"db68031b-83ff-4c2a-f5dc-370f3b356bb4"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["primary_tag\n","rap                        2463\n","pop                        2461\n","country                    1596\n","r&b                        1346\n","rock                       1110\n","electronic                  514\n","chicago drill                 2\n","#fliptheswitchchallenge       1\n","rage                          1\n","drill                         1\n","funk                          1\n","edm                           1\n","hip-hop                       1\n","trap                          1\n","hyphy                         1\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["# keep only classes with more than 2 samples\n","df = df.groupby(\"primary_tag\").filter(lambda x: len(x) > 2)\n","print(len(df))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BdvOoCvngi6a","executionInfo":{"status":"ok","timestamp":1756376134146,"user_tz":-120,"elapsed":10,"user":{"displayName":"Jan","userId":"04834686519003542727"}},"outputId":"2bd27879-66b8-45cb-8a0b-70605755a055"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["9490\n"]}]},{"cell_type":"code","source":["print(df[\"primary_tag\"].value_counts())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P4vBPS_6hADA","executionInfo":{"status":"ok","timestamp":1756376135278,"user_tz":-120,"elapsed":9,"user":{"displayName":"Jan","userId":"04834686519003542727"}},"outputId":"ea66f2ef-63ed-4301-b1c9-efe5fa8e2206"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["primary_tag\n","rap           2463\n","pop           2461\n","country       1596\n","r&b           1346\n","rock          1110\n","electronic     514\n","Name: count, dtype: int64\n"]}]},{"cell_type":"markdown","source":["Split into Train, Validation, and Test Sets:"],"metadata":{"id":"VzhT9kCAh33o"}},{"cell_type":"code","source":["# stratify keeps genre distribution similar.\n","train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df[\"primary_tag\"], random_state=42)\n","val_df, test_df   = train_test_split(temp_df, test_size=0.5, stratify=temp_df[\"primary_tag\"], random_state=42)"],"metadata":{"id":"FXasv0zEd5DZ","executionInfo":{"status":"ok","timestamp":1756376138460,"user_tz":-120,"elapsed":9,"user":{"displayName":"Jan","userId":"04834686519003542727"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["print(f\"Dataset sizes:\\n- Training: {len(train_df)}\\n- Validation: {len(val_df)}\\n- Test: {len(test_df)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n7H96jALiLHX","executionInfo":{"status":"ok","timestamp":1756376139764,"user_tz":-120,"elapsed":20,"user":{"displayName":"Jan","userId":"04834686519003542727"}},"outputId":"dfffd2b0-ac72-4dc7-8a55-aab1ff6471a8"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset sizes:\n","- Training: 6643\n","- Validation: 1423\n","- Test: 1424\n"]}]},{"cell_type":"markdown","source":["Preparing datasets:"],"metadata":{"id":"tsmc0fu9eCdt"}},{"cell_type":"code","source":["# Training + Validation + Test\n","\n","unique_genres = df['primary_tag'].unique()\n","genre_to_id = {genre: i for i, genre in enumerate(unique_genres)}\n","print(genre_to_id)\n","\n","# train set\n","train_set = []\n","for _, row in train_df.iterrows():\n","    train_set.append(InputExample(\n","        texts=[row['lyrics_clean']],\n","        label=genre_to_id[row['primary_tag']]))\n","\n","# validation set\n","val_set = []\n","for _, row in val_df.iterrows():\n","    val_set.append(InputExample(\n","        texts=[row['lyrics_clean']],\n","        label=genre_to_id[row['primary_tag']]))\n","\n","# test set\n","test_set = []\n","for _, row in test_df.iterrows():\n","    test_set.append(InputExample(\n","        texts=[row['lyrics_clean']],\n","        label=genre_to_id[row['primary_tag']]))\n","\n","print(f\"\\nCreated {len(train_set)} examples for training (lyric, label format).\")\n","print(f\"Created {len(val_set)} examples for validation loss (lyric, label format).\")\n","print(f\"Created {len(test_set)} examples for test loss (lyric, label format).\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ULsJ-4S_irAf","executionInfo":{"status":"ok","timestamp":1756376142379,"user_tz":-120,"elapsed":538,"user":{"displayName":"Jan","userId":"04834686519003542727"}},"outputId":"3fc9276f-be4b-4e26-b35f-eef715a2ca89"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["{'pop': 0, 'r&b': 1, 'rap': 2, 'electronic': 3, 'rock': 4, 'country': 5}\n","\n","Created 6643 examples for training (lyric, label format).\n","Created 1423 examples for validation loss (lyric, label format).\n","Created 1424 examples for test loss (lyric, label format).\n"]}]},{"cell_type":"code","source":["from collections import Counter\n","\n","labels = [ex.label for ex in test_set]\n","print(Counter(labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R-4hGnIyD6bV","executionInfo":{"status":"ok","timestamp":1756290330598,"user_tz":-120,"elapsed":13,"user":{"displayName":"Jan","userId":"17384221260929809032"}},"outputId":"d531a637-cfac-4e1b-f83e-44644f05c16a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Counter({2: 370, 0: 369, 5: 240, 1: 202, 4: 166, 3: 77})\n"]}]},{"cell_type":"code","source":["# Evaluation + Test (explicit Triplets)\n","\n","def create_triplets(input_df):\n","    \"\"\"\n","    Generates triplets (anchor, positive, negative) from a dataframe.\n","    - anchor: A song lyric.\n","    - positive: A different song lyric from the same genre.\n","    - negative: A song lyric from a different genre.\n","    \"\"\"\n","    random.seed(42)\n","    triplets = []\n","\n","    # create dictionary.\n","    lyrics_by_genre = input_df.groupby('primary_tag')['lyrics_clean'].apply(list).to_dict()\n","    all_genres = list(lyrics_by_genre.keys())\n","\n","    for _, row in input_df.iterrows():\n","        anchor_lyric = row['lyrics_clean']\n","        positive_genre = row['primary_tag']\n","\n","        # --- find positive example ---\n","        # get all lyrics of the same genre, excluding the anchor itself\n","        positive_pool = [lyric for lyric in lyrics_by_genre[positive_genre] if lyric != anchor_lyric]\n","        if not positive_pool:\n","            continue # skip if no other song of the same genre exists in the set\n","\n","        positive_lyric = random.choice(positive_pool)\n","\n","        # --- find negative example ---\n","        # choose a random genre that is different from the positive one\n","        negative_genre_options = [g for g in all_genres if g != positive_genre]\n","        if not negative_genre_options:\n","            continue # skip if there's only one genre in the entire dataset\n","\n","        negative_genre = random.choice(negative_genre_options)\n","        negative_lyric = random.choice(lyrics_by_genre[negative_genre])\n","\n","        # the TripletEvaluator in sentence-transformers expects InputExample with three texts\n","        triplets.append(InputExample(texts=[anchor_lyric, positive_lyric, negative_lyric]))\n","\n","    return triplets\n","\n","# create the triplet sets for evaluation.\n","triplet_val = create_triplets(val_df)\n","triplet_test = create_triplets(test_df)\n","triplet_train = create_triplets(train_df)\n","\n","print(f\"Created {len(triplet_val)} triplets for the final test set.\")\n","print(f\"Created {len(triplet_test)} triplets for validation evaluation.\")\n","print(f\"Created {len(triplet_train)} triplets for the final train set.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AJMIgF3LeQ_X","executionInfo":{"status":"ok","timestamp":1756376884403,"user_tz":-120,"elapsed":874,"user":{"displayName":"Jan","userId":"04834686519003542727"}},"outputId":"70b83146-65d9-4baa-a0cb-b0cac7fb8bf8"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Created 1423 triplets for the final test set.\n","Created 1424 triplets for validation evaluation.\n","Created 6643 triplets for the final train set.\n"]}]},{"cell_type":"code","source":["def create_pairs(input_df):\n","    \"\"\"\n","    Generates labeled pairs (lyric_1, lyric_2, label) where:\n","    - label = 1 if same genre\n","    - label = 0 if different genre\n","\n","    Returns a DataFrame with columns: lyric_1, lyric_2, label\n","    \"\"\"\n","    random.seed(42)\n","    pairs = []\n","\n","    #same as triplet function\n","    lyrics_by_genre = input_df.groupby('primary_tag')['lyrics_clean'].apply(list).to_dict()\n","    all_genres = list(lyrics_by_genre.keys())\n","\n","    for _, row in input_df.iterrows():\n","        anchor_lyric = row['lyrics_clean']\n","        anchor_genre = row['primary_tag']\n","\n","        #positives\n","        positive_pool = [lyric for lyric in lyrics_by_genre[anchor_genre] if lyric != anchor_lyric]\n","        if positive_pool:\n","            positive_lyric = random.choice(positive_pool)\n","            pairs.append({\n","                'lyric_1': anchor_lyric,\n","                'lyric_2': positive_lyric,\n","                'label': 1\n","            })\n","\n","        #negative pairs\n","        negative_genres = [g for g in all_genres if g != anchor_genre and lyrics_by_genre[g]]\n","        if negative_genres:\n","            negative_genre = random.choice(negative_genres)\n","            negative_lyric = random.choice(lyrics_by_genre[negative_genre])\n","            pairs.append({\n","                'lyric_1': anchor_lyric,\n","                'lyric_2': negative_lyric,\n","                'label': 0\n","            })\n","\n","    return pd.DataFrame(pairs)\n","\n","\n","# create the triplet sets for evaluation.\n","pairs_train = create_pairs(train_df)\n","pairs_val = create_pairs(val_df)\n","pairs_test = create_pairs(test_df)\n","\n","print(f\"Created {len(pairs_train)} pairs for the final train set.\")\n","print(f\"Created {len(pairs_val)} pairs for validation evaluation.\")\n","print(f\"Created {len(pairs_test)} pairs for the final test set.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U3SeGs2yvGpx","executionInfo":{"status":"ok","timestamp":1756376806433,"user_tz":-120,"elapsed":1473,"user":{"displayName":"Jan","userId":"04834686519003542727"}},"outputId":"b53cbdec-1e79-4d5e-9ab2-c24648b99ded"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Created 13286 pairs for the final train set.\n","Created 2846 pairs for validation evaluation.\n","Created 2848 pairs for the final test set.\n"]}]},{"cell_type":"markdown","source":["Saving files to CSV:"],"metadata":{"id":"tgPp_3sSef5B"}},{"cell_type":"code","source":["def to_dataframe_label(examples):\n","    return pd.DataFrame({\n","        'lyric': [ex.texts[0] for ex in examples],\n","        'label': [ex.label for ex in examples]})\n","\n","def to_dataframe_triplets(examples):\n","    return pd.DataFrame({\n","        'anchor': [ex.texts[0] for ex in examples],\n","        'positive': [ex.texts[1] for ex in examples],\n","        'negative': [ex.texts[2] for ex in examples]})\n","\n","\n","# convert to DataFrames\n","label_train_df = to_dataframe_label(train_set)\n","label_val_df = to_dataframe_label(val_set)\n","label_test_df = to_dataframe_label(test_set)\n","triplet_val_df = to_dataframe_triplets(triplet_val)\n","triplet_test_df = to_dataframe_triplets(triplet_test)\n","triplet_train_df = to_dataframe_triplets(triplet_train)\n","\n","\n","# save train/val/test splits for both approaches\n","label_train_df.to_csv('label_train.csv', index=False)\n","label_val_df.to_csv('label_val.csv', index=False)\n","label_test_df.to_csv('label_test.csv', index=False)\n","triplet_val_df.to_csv('triplets_val.csv', index=False)\n","triplet_test_df.to_csv('triplets_test.csv', index=False)\n","triplet_train_df.to_csv('triplets_train.csv', index=False)\n","pairs_train.to_csv('pairs_train.csv', index=False)\n","pairs_val.to_csv('pairs_val.csv', index=False)\n","pairs_test.to_csv('pairs_test.csv', index=False)"],"metadata":{"id":"fupmo4_sehfJ","executionInfo":{"status":"ok","timestamp":1756376894835,"user_tz":-120,"elapsed":2293,"user":{"displayName":"Jan","userId":"04834686519003542727"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","\n","files.download('label_train.csv')\n","files.download('label_val.csv')\n","files.download('label_test.csv')\n","files.download('triplets_train')\n","files.download('triplets_val.csv')\n","files.download('triplets_test.csv')\n","files.download('pairs_train')\n","files.download('pairs_val.csv')\n","files.download('pairs_test.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"uGZnw_UTkv1r","executionInfo":{"status":"ok","timestamp":1755780368718,"user_tz":-120,"elapsed":4,"user":{"displayName":"Nicole Kloss","userId":"01214507128086168572"}},"outputId":"045a94f1-5dfd-416a-e73a-946f8506c9d3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_36171677-602f-4d98-83ba-0e6136311faa\", \"train_set_for_loss.csv\", 3083444)"]},"metadata":{}}]}]}